exp:
  name: ${conf.dataset.obj_name}
  phase: train  # or val, test, predict
  predict_after_train: true
  test_after_train: true
  resume: false
  ckpt_path: ckpt
  exp_path: exp/diligentmv
  runs_dir: runs
  trial_name: null
  code_path: code
  save_dir: save
  config_path: configs
  tag: ""
  seed: 42

hydra:
  run:
    dir: ./
  output_subdir: null

trainer:
  max_steps: 20000
  log_every_n_steps: 100
  num_sanity_val_steps: 1
  val_check_interval: 1000
  limit_val_batches: 1 # number of images to validate. Set to 1 (Not 1.0) to validate only one image.
  limit_train_batches: 1.
  enable_progress_bar: true
  precision: 16

checkpoint:
  monitor: global_step
  mode: max
  save_top_k: 2
  every_n_train_steps: 5000
  save_last: true
  save_on_train_epoch_end: false
  filename: "{global_step}-{epoch}"

dataset:
  obj_name: buddha
  root_dir: ./data/DiLiGenT-MV
  data_dir: ${conf.dataset.root_dir}/${conf.dataset.obj_name}

  img_dirname: image
  img_ext: "png"
  img_load_fn: diligentmv_img

  mask_dirname: mask
  mask_ext: "png"
  mask_load_fn: mask

  normal_dirname: normal_camera_space_GT
  normal_ext: "exr"
  normal_load_fn: diligentmv_normal

  cameras_fpath: ${conf.dataset.data_dir}/camera_params.json

  light_dir_file: ${conf.model.light.light_dir_file}
  light_int_file: ${conf.model.light.light_int_file}
  sample_img_fname: "V00L00.png"
  sample_mask_fname: "V00.png"
  train:
    name: dataset_train
    init_num_rays_per_batch: 4096
    max_num_rays_per_batch: 4096
    img_downscale: 1 # specify training image size by img_downscale
    view_light_index_fname: view_18_light_32
    view_light_index_file: ./configs/view_light_indices/${conf.dataset.train.view_light_index_fname}.txt

  val:
    name: dataset_val
    img_downscale: 1 # for validation rendering
    view_light_index_fname: view_18_light_32
    view_light_index_file: ./configs/view_light_indices/${conf.dataset.val.view_light_index_fname}.txt
    validataion_crop: true  # only render the image regions within the mask for acceleration

  test:
    name: dataset_test
    img_downscale: 1 # for rendering of test images
    img_mesh_downscale: 1 # for mesh visualization
    gt_mesh_fpath: ${conf.dataset.data_dir}/mesh_Gt.ply
    view_light_index_fname: view_20_light_96
    view_light_index_file: ./configs/view_light_indices/${conf.dataset.test.view_light_index_fname}.txt
    validataion_crop: true  # only render the image regions within the mask for acceleration

#  predict_targets: ["predict_mesh", "predict_brdf", "predict_relighting"] # specify which predictions to make during export phase.
  predict_targets: ["predict_brdf", "predict_relighting"]
  predict_mesh:
    dataset_name: mesh_export
    predict_step_fn_name: _predict_step_mesh
    gt_mesh_fpath: ${conf.dataset.data_dir}/mesh_Gt.ply
    bbox_res: 512  # in voxel
    chunk_size: 2097152
    export_brdf_latent: false  # whether to export BRDF latent features as RGB colors
    view_light_index_fname: view_20_light_1  # for visualizing the mesh. Only unique views will be used.
    view_light_index_file: ./configs/view_light_indices/${conf.dataset.val.view_light_index_fname}.txt
    img_downscale: 1 # for mesh rendering

  predict_brdf:
    dataset_name: brdf_render
    predict_step_fn_name: _predict_step_brdf
    img_downscale: 1 # for brdf map rendering
    brdf_sphere_res: 64 # in pixel
    view_light_index: "V00L00" # the view for brdf map rendering. Align with theã€€image name.
    light_direction: [0, 0, -1]  # ensure negative z component. Will be normalized in the code.

  predict_relighting: # for novel-view relighting rendering
    dataset_name: relighting
    predict_step_fn_name: _predict_step_relighting
    img_width: 512 # in pixel
    img_height: 512 # in pixel
    camera_focal_length_to_img_width_ratio: 5.0 # focal length = camera_focal_length_to_img_width * img_width
    light_frames: 20
    light_elevation: 60 # in degree
    camera_frames: 60
    camera_elevation: 10 # in degree
    camera_distance: 8 # distance from the object center, in object space (i.e., the object is in a unit sphere)
    camera_lookat: [0, 0, 0] # in object space
    view_light_idx_sample: "V00L00"

model:
  name: mvscps
  radius: 1.0
  num_samples_per_ray: 1024
  num_lights: ${conf.dataset.train_num_lights}
  train_num_rays: 512
  max_train_num_rays: 4096
  grid_prune: true
  grid_prune_occ_thre: 0.1
  dynamic_ray_sampling: true
  batch_image_sampling: true
  randomized: true
  ray_chunk: 4096
  cos_anneal_end: 5000
  save_mesh_interval: ${conf.trainer.max_steps}
  light:
    init_light_dir: [0, 0, -1.]
    init_intensity: 1.0
    use_gt_light: false
    light_dir_file: ${conf.dataset.data_dir}/light_directions.txt
    light_int_file: ${conf.dataset.data_dir}/light_intensities.txt
    view_light_index_fname_train: ${conf.dataset.train.view_light_index_file}
  variance:
    init_val: 0.3
    modulate: false
  geometry:
    name: neural_sdf
    radius: ${conf.model.radius}
    feature_dim: 64
    grad_type: analytic
    isosurface:
      method: mc
      resolution: 512
      chunk: 2097152
      threshold: 0.
    xyz_encoding_config:
      otype: HashGrid
      n_levels: 14
      n_features_per_level: 2
      log2_hashmap_size: 19
      base_resolution: 32
      per_level_scale: 1.3195079107728942
      include_xyz: true
    mlp_network_config:
      otype: VanillaMLP
      activation: ReLU
      output_activation: none
      n_neurons: 64
      n_hidden_layers: 1
      sphere_init: true
      sphere_init_radius: 0.5
      weight_norm: true
  brdf:
    name: neural_brdf
    use_ae: true
    num_ae: 5
    input_feature_dim: ${add:${conf.model.geometry.feature_dim}, -1}
    dir_encoding_config:
      otype: SphericalHarmonics
      degree: 2
    mlp_network_config:
      otype: VanillaMLP
      activation: ReLU
      output_activation: ReLU
      n_neurons: 64
      n_hidden_layers: 2
  shadow:
    name: shadow-mapping
    input_feature_dim: ${add:${conf.model.geometry.feature_dim}, -1} # surface normal as additional input
    dir_encoding_config:
      otype: SphericalHarmonics
      degree: 3
    mlp_network_config:
      otype: VanillaMLP
      activation: ReLU
      output_activation: sigmoid
      n_neurons: 64
      n_hidden_layers: 2

system:
  name: mvscps
  loss:
    lambda_rgb_mse: 0.
    lambda_rgb_l1: 0.
    lambda_rgb_weighted_l1: 1.
    lambda_rgb_weighted_mse: 0.
    lambda_mask: 1.
    lambda_eikonal: 1.
  optimizer:
    name: AdamW
    args:
      lr: 0.01
      betas: [0.9, 0.99]
      eps: 1.e-15
    params:
      geometry:
        lr: 0.01
      brdf:
        lr: 0.01
      variance:
        lr: 0.001
      lighting:
        lr: 0.001
      shadow_mapping:
        lr: 0.001

  scheduler:
    name: SequentialLR
    constant_steps: 5000
    interval: step
    milestones:
      - ${conf.system.scheduler.constant_steps}
    schedulers:
      - name: ConstantLR
        args:
          factor: 1.0
          total_iters: ${conf.system.scheduler.constant_steps}
      - name: ExponentialLR
        args:
          gamma: ${calc_exp_lr_decay_rate:0.1,${sub:${conf.trainer.max_steps},${conf.system.scheduler.constant_steps}}}



export:
  chunk_size: 2097152
  export_spatial_latent: false


